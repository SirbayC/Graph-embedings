{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:58.219282600Z",
     "start_time": "2024-01-27T17:19:57.976285Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Articles Dataset\n",
    "\n",
    "We provide a dataset of medium articles which have to be tagged to corresponding topics (software-development, artificial intellignece, Ui/UX). Along with articles we have subscriptions lists. The articles may be related by common subscription lists. The goal is to exploit this naturally occuring network structure for classifying articles to topics. Hence, it is a 3-way node classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:58.619283900Z",
     "start_time": "2024-01-27T17:19:57.995285Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(dir_name: str, file_name: str):\n",
    "    \"\"\"Read the medium articles with lists\n",
    "\n",
    "    Args:\n",
    "        dir_name (str): Root directory of the medium title files and lists.\n",
    "\n",
    "    Returns:\n",
    "        final_data: merged dataframes with articles and lists\n",
    "    \"\"\"\n",
    "\n",
    "    final_data = pd.read_csv(dir_name+\"/\"+file_name+\".csv\")\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.448283300Z",
     "start_time": "2024-01-27T17:19:58.015284800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://medium.com/@maniakacademy/code-demo-sh...</td>\n",
       "      <td>Code/Demo Share: Palo Alto Firewall Network In...</td>\n",
       "      <td>IP is broken as a unit of Control! IDENTITY as...</td>\n",
       "      <td>Sebastian Maniak</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>https://medium.com/@zemmali1990/list/aws-49f68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://medium.com/towards-artificial-intellig...</td>\n",
       "      <td>Clustering using Social Graph Network</td>\n",
       "      <td>A Social Graph Network can be formed when ther...</td>\n",
       "      <td>Naveed Ahmed Janvekar</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>https://medium.com/@TomaszCieplak/list/graph-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://medium.com/@sarafparam/transformers-fo...</td>\n",
       "      <td>Transformers for Time-Series</td>\n",
       "      <td>Forecasting still remains to be dominated by S...</td>\n",
       "      <td>Param Saraf</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>https://medium.com/@sergiobonato/list/time-ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://medium.com/towards-data-science/review...</td>\n",
       "      <td>Reviewing A/B Testing Course by Google on Udacity</td>\n",
       "      <td>Read to find out how A/B tests are performed a...</td>\n",
       "      <td>Suyash Maheshwari</td>\n",
       "      <td>2020-05-10</td>\n",
       "      <td>https://medium.com/@online.rajib/list/ml-c2cac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://medium.com/towards-data-science/a-comp...</td>\n",
       "      <td>A Comprehensive Hands-on Guide to Transfer Lea...</td>\n",
       "      <td>Deep Learning on Steroids with the Power of Kn...</td>\n",
       "      <td>Dipanjan (DJ) Sarkar</td>\n",
       "      <td>2018-11-14</td>\n",
       "      <td>https://medium.com/@farhanhanavi07/list/deep-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27713</th>\n",
       "      <td>https://medium.com/cometheartbeat/deep-learnin...</td>\n",
       "      <td>Deep Learning Techniques you Should Know in 2022</td>\n",
       "      <td>Over the years, Deep Learning has really taken...</td>\n",
       "      <td>Nisha Arya Ahmed</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>https://medium.com/@vigguvenki/list/deep-learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27714</th>\n",
       "      <td>https://medium.com/towardsdev/intro-to-object-...</td>\n",
       "      <td>Intro to Object-Oriented Programming For Data ...</td>\n",
       "      <td>Implement a simple Linear Regression with OOP ...</td>\n",
       "      <td>Bex T.</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>https://medium.com/@or.matalon2/list/oop-4aad5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27715</th>\n",
       "      <td>https://medium.com/towards-data-science/learn-...</td>\n",
       "      <td>Learn Enough Docker to be Useful</td>\n",
       "      <td>Part 1: The Conceptual Landscape — Containers ...</td>\n",
       "      <td>Jeff Hale</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>https://medium.com/@vaibhavb2473/list/machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27716</th>\n",
       "      <td>https://medium.com/berndruecker/moving-from-em...</td>\n",
       "      <td>Moving from embedded to remote workflow engines</td>\n",
       "      <td>For a long time, we have advocated for an arch...</td>\n",
       "      <td>Bernd Rücker</td>\n",
       "      <td>2022-02-08</td>\n",
       "      <td>https://medium.com/@giamma80/list/java-3c31810...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27717</th>\n",
       "      <td>https://guillaume-weingertner.medium.com/5-ste...</td>\n",
       "      <td>5 Steps to Build Beautiful Bar Charts with Python</td>\n",
       "      <td>How to use the full capabilities of Matplotlib...</td>\n",
       "      <td>Guillaume Weingertner</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>https://luistrigueiros.medium.com/list/python-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27718 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article  \\\n",
       "0      https://medium.com/@maniakacademy/code-demo-sh...   \n",
       "1      https://medium.com/towards-artificial-intellig...   \n",
       "2      https://medium.com/@sarafparam/transformers-fo...   \n",
       "3      https://medium.com/towards-data-science/review...   \n",
       "4      https://medium.com/towards-data-science/a-comp...   \n",
       "...                                                  ...   \n",
       "27713  https://medium.com/cometheartbeat/deep-learnin...   \n",
       "27714  https://medium.com/towardsdev/intro-to-object-...   \n",
       "27715  https://medium.com/towards-data-science/learn-...   \n",
       "27716  https://medium.com/berndruecker/moving-from-em...   \n",
       "27717  https://guillaume-weingertner.medium.com/5-ste...   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Code/Demo Share: Palo Alto Firewall Network In...   \n",
       "1                  Clustering using Social Graph Network   \n",
       "2                           Transformers for Time-Series   \n",
       "3      Reviewing A/B Testing Course by Google on Udacity   \n",
       "4      A Comprehensive Hands-on Guide to Transfer Lea...   \n",
       "...                                                  ...   \n",
       "27713   Deep Learning Techniques you Should Know in 2022   \n",
       "27714  Intro to Object-Oriented Programming For Data ...   \n",
       "27715                   Learn Enough Docker to be Useful   \n",
       "27716    Moving from embedded to remote workflow engines   \n",
       "27717  5 Steps to Build Beautiful Bar Charts with Python   \n",
       "\n",
       "                                                subtitle  \\\n",
       "0      IP is broken as a unit of Control! IDENTITY as...   \n",
       "1      A Social Graph Network can be formed when ther...   \n",
       "2      Forecasting still remains to be dominated by S...   \n",
       "3      Read to find out how A/B tests are performed a...   \n",
       "4      Deep Learning on Steroids with the Power of Kn...   \n",
       "...                                                  ...   \n",
       "27713  Over the years, Deep Learning has really taken...   \n",
       "27714  Implement a simple Linear Regression with OOP ...   \n",
       "27715  Part 1: The Conceptual Landscape — Containers ...   \n",
       "27716  For a long time, we have advocated for an arch...   \n",
       "27717  How to use the full capabilities of Matplotlib...   \n",
       "\n",
       "                      author        date  \\\n",
       "0           Sebastian Maniak  2022-08-17   \n",
       "1      Naveed Ahmed Janvekar  2022-01-29   \n",
       "2                Param Saraf  2020-10-20   \n",
       "3          Suyash Maheshwari  2020-05-10   \n",
       "4       Dipanjan (DJ) Sarkar  2018-11-14   \n",
       "...                      ...         ...   \n",
       "27713       Nisha Arya Ahmed  2022-04-21   \n",
       "27714                 Bex T.  2021-04-12   \n",
       "27715              Jeff Hale  2019-01-09   \n",
       "27716           Bernd Rücker  2022-02-08   \n",
       "27717  Guillaume Weingertner  2023-01-23   \n",
       "\n",
       "                                                    list  \n",
       "0      https://medium.com/@zemmali1990/list/aws-49f68...  \n",
       "1      https://medium.com/@TomaszCieplak/list/graph-d...  \n",
       "2      https://medium.com/@sergiobonato/list/time-ser...  \n",
       "3      https://medium.com/@online.rajib/list/ml-c2cac...  \n",
       "4      https://medium.com/@farhanhanavi07/list/deep-l...  \n",
       "...                                                  ...  \n",
       "27713  https://medium.com/@vigguvenki/list/deep-learn...  \n",
       "27714  https://medium.com/@or.matalon2/list/oop-4aad5...  \n",
       "27715  https://medium.com/@vaibhavb2473/list/machine-...  \n",
       "27716  https://medium.com/@giamma80/list/java-3c31810...  \n",
       "27717  https://luistrigueiros.medium.com/list/python-...  \n",
       "\n",
       "[27718 rows x 6 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.read_csv(\"data/pipeline_assignment_data/full_data_without_labels.csv\")\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.462283300Z",
     "start_time": "2024-01-27T17:19:58.332284700Z"
    }
   },
   "outputs": [],
   "source": [
    "train = read_data(\"data/pipeline_assignment_data\",\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.499283800Z",
     "start_time": "2024-01-27T17:19:58.603285400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>list</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2291</td>\n",
       "      <td>https://medium.com/towards-data-science/how-to...</td>\n",
       "      <td>How to Use the IBM Watson Tone Analyzer to Per...</td>\n",
       "      <td>How to use the IBM Watson Artificial Intellige...</td>\n",
       "      <td>Graham Harrison</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>https://medium.com/@4ndres.gaviria/list/nlp-to...</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7292</td>\n",
       "      <td>https://medium.com/towards-data-science/surviv...</td>\n",
       "      <td>Survival Analysis: Intuition &amp; Implementation ...</td>\n",
       "      <td>There is a statistical technique which can ans...</td>\n",
       "      <td>Anurag Pandey</td>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>https://medium.com/@jz5246/list/analytics-559c...</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6768</td>\n",
       "      <td>https://medium.com/experience-stack/embrace-co...</td>\n",
       "      <td>Embrace Complexity (Part 1)</td>\n",
       "      <td>Why all organisations should build internal ne...</td>\n",
       "      <td>Tony Seale</td>\n",
       "      <td>2022-02-04</td>\n",
       "      <td>https://medium.com/@yasha.brener/list/data-man...</td>\n",
       "      <td>software-development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15003</td>\n",
       "      <td>https://medium.com/towards-data-science/every-...</td>\n",
       "      <td>Every Complex DataFrame Manipulation, Explaine...</td>\n",
       "      <td>Melts, pivots, joins, explodes, &amp; more — Panda...</td>\n",
       "      <td>Andre Ye</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>https://medium.com/@4ndres.gaviria/list/dataop...</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19782</td>\n",
       "      <td>https://medium.com/towards-data-science/macroe...</td>\n",
       "      <td>Macroeconomic &amp; Financial Factors and Ordinary...</td>\n",
       "      <td>Econometrics model using Arbitrage Pricing The...</td>\n",
       "      <td>Sarit Maitra</td>\n",
       "      <td>2020-06-27</td>\n",
       "      <td>https://medium.com/@halo9pan/list/quantitative...</td>\n",
       "      <td>software-development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>14424</td>\n",
       "      <td>https://medium.com/towards-data-science/normal...</td>\n",
       "      <td>Normalization vs Standardization — Quantitativ...</td>\n",
       "      <td>Stop using StandardScaler from Sklearn as a de...</td>\n",
       "      <td>Shay Geller</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>https://medium.com/@farhanhanavi07/list/applie...</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>18949</td>\n",
       "      <td>https://medium.com/@petruknisme/getting-starte...</td>\n",
       "      <td>Getting Started with Covenant C2 for Red Teaming</td>\n",
       "      <td>Command and Control is part of Red Teaming tac...</td>\n",
       "      <td>Aan</td>\n",
       "      <td>2021-11-21</td>\n",
       "      <td>https://medium.com/@jimmy.winghang/list/mitre-...</td>\n",
       "      <td>software-development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>9305</td>\n",
       "      <td>https://medium.com/towards-data-science/how-to...</td>\n",
       "      <td>How to Create a Vector-Based Movie Recommendat...</td>\n",
       "      <td>Building a movie recommendation system using t...</td>\n",
       "      <td>Michelangiolo Mazzeschi</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>https://medium.com/@subhasis.jethy/list/recomm...</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>24337</td>\n",
       "      <td>https://medium.com/towards-data-science/how-to...</td>\n",
       "      <td>How to Use Pandas for Big Data</td>\n",
       "      <td>Run distributed workload with Pandas on Spark ...</td>\n",
       "      <td>Edwin Tan</td>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>https://medium.com/@jethro_torczon/list/big-da...</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>7662</td>\n",
       "      <td>https://medium.com/towards-data-science/a-prac...</td>\n",
       "      <td>A Practical Guide to Build an Enterprise Knowl...</td>\n",
       "      <td>How to solve the practical problems when build...</td>\n",
       "      <td>Xu LIANG</td>\n",
       "      <td>2019-10-23</td>\n",
       "      <td>https://medium.com/@adambouras1/list/semantic-...</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3950 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            article  \\\n",
       "0      2291  https://medium.com/towards-data-science/how-to...   \n",
       "1      7292  https://medium.com/towards-data-science/surviv...   \n",
       "2      6768  https://medium.com/experience-stack/embrace-co...   \n",
       "3     15003  https://medium.com/towards-data-science/every-...   \n",
       "4     19782  https://medium.com/towards-data-science/macroe...   \n",
       "...     ...                                                ...   \n",
       "3945  14424  https://medium.com/towards-data-science/normal...   \n",
       "3946  18949  https://medium.com/@petruknisme/getting-starte...   \n",
       "3947   9305  https://medium.com/towards-data-science/how-to...   \n",
       "3948  24337  https://medium.com/towards-data-science/how-to...   \n",
       "3949   7662  https://medium.com/towards-data-science/a-prac...   \n",
       "\n",
       "                                                  title  \\\n",
       "0     How to Use the IBM Watson Tone Analyzer to Per...   \n",
       "1     Survival Analysis: Intuition & Implementation ...   \n",
       "2                           Embrace Complexity (Part 1)   \n",
       "3     Every Complex DataFrame Manipulation, Explaine...   \n",
       "4     Macroeconomic & Financial Factors and Ordinary...   \n",
       "...                                                 ...   \n",
       "3945  Normalization vs Standardization — Quantitativ...   \n",
       "3946   Getting Started with Covenant C2 for Red Teaming   \n",
       "3947  How to Create a Vector-Based Movie Recommendat...   \n",
       "3948                     How to Use Pandas for Big Data   \n",
       "3949  A Practical Guide to Build an Enterprise Knowl...   \n",
       "\n",
       "                                               subtitle  \\\n",
       "0     How to use the IBM Watson Artificial Intellige...   \n",
       "1     There is a statistical technique which can ans...   \n",
       "2     Why all organisations should build internal ne...   \n",
       "3     Melts, pivots, joins, explodes, & more — Panda...   \n",
       "4     Econometrics model using Arbitrage Pricing The...   \n",
       "...                                                 ...   \n",
       "3945  Stop using StandardScaler from Sklearn as a de...   \n",
       "3946  Command and Control is part of Red Teaming tac...   \n",
       "3947  Building a movie recommendation system using t...   \n",
       "3948  Run distributed workload with Pandas on Spark ...   \n",
       "3949  How to solve the practical problems when build...   \n",
       "\n",
       "                       author        date  \\\n",
       "0             Graham Harrison  2022-01-02   \n",
       "1               Anurag Pandey  2019-01-06   \n",
       "2                  Tony Seale  2022-02-04   \n",
       "3                    Andre Ye  2020-07-22   \n",
       "4                Sarit Maitra  2020-06-27   \n",
       "...                       ...         ...   \n",
       "3945              Shay Geller  2019-04-04   \n",
       "3946                      Aan  2021-11-21   \n",
       "3947  Michelangiolo Mazzeschi  2021-12-10   \n",
       "3948                Edwin Tan  2022-01-25   \n",
       "3949                 Xu LIANG  2019-10-23   \n",
       "\n",
       "                                                   list  \\\n",
       "0     https://medium.com/@4ndres.gaviria/list/nlp-to...   \n",
       "1     https://medium.com/@jz5246/list/analytics-559c...   \n",
       "2     https://medium.com/@yasha.brener/list/data-man...   \n",
       "3     https://medium.com/@4ndres.gaviria/list/dataop...   \n",
       "4     https://medium.com/@halo9pan/list/quantitative...   \n",
       "...                                                 ...   \n",
       "3945  https://medium.com/@farhanhanavi07/list/applie...   \n",
       "3946  https://medium.com/@jimmy.winghang/list/mitre-...   \n",
       "3947  https://medium.com/@subhasis.jethy/list/recomm...   \n",
       "3948  https://medium.com/@jethro_torczon/list/big-da...   \n",
       "3949  https://medium.com/@adambouras1/list/semantic-...   \n",
       "\n",
       "                       labels  \n",
       "0     artificial-intelligence  \n",
       "1     artificial-intelligence  \n",
       "2        software-development  \n",
       "3     artificial-intelligence  \n",
       "4        software-development  \n",
       "...                       ...  \n",
       "3945  artificial-intelligence  \n",
       "3946     software-development  \n",
       "3947  artificial-intelligence  \n",
       "3948  artificial-intelligence  \n",
       "3949  artificial-intelligence  \n",
       "\n",
       "[3950 rows x 8 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = read_data(\"data/pipeline_assignment_data\",\"test\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.501284400Z",
     "start_time": "2024-01-27T17:19:58.665285600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "software-development       11586\n",
       "artificial-intelligence    10646\n",
       "ux                           150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.501284400Z",
     "start_time": "2024-01-27T17:19:58.679283700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "software-development       2022\n",
       "artificial-intelligence    1899\n",
       "ux                           29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.501284400Z",
     "start_time": "2024-01-27T17:19:58.695284200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        With Kazam and ffmpeg on GNU/Linux systems — I...\n",
       "1        A tutorial on how to deploy SpaCy with AWS. — ...\n",
       "2        Are you a senior analyst growing towards a man...\n",
       "3        My Dart Google Summer of Code 2021 experience....\n",
       "4        Understand how to discover multicollinearity i...\n",
       "                               ...                        \n",
       "22377    How to design your own graph using TigerGraph ...\n",
       "22378    Automate the editing of explainer videos to cr...\n",
       "22379    Faster Python Code With Numba — The Speed Issu...\n",
       "22380    Julia is used for a lot of deeply technical ap...\n",
       "22381    For years now, most of us have heard the word ...\n",
       "Name: subtitle, Length: 22382, dtype: object"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.subtitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that the separated \"train\" and \"test\" data also contain an index column. The value in that index corresponds to the index of the row that article appears in the full data.\n",
    "\n",
    "Note that some of the articles are repeated (when considering articles uniquely identified by their urls). Thus it might not be necessarily wise to use the index of an article itself as a unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.502284100Z",
     "start_time": "2024-01-27T17:19:58.712284200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27718\n",
      "26660\n"
     ]
    }
   ],
   "source": [
    "article_links = final_data[\"article\"]\n",
    "print(len(article_links))\n",
    "print(len(set(article_links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Label conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.502284100Z",
     "start_time": "2024-01-27T17:19:58.727283600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           software-development\n",
      "1        artificial-intelligence\n",
      "2        artificial-intelligence\n",
      "3           software-development\n",
      "4           software-development\n",
      "                  ...           \n",
      "22377    artificial-intelligence\n",
      "22378       software-development\n",
      "22379    artificial-intelligence\n",
      "22380       software-development\n",
      "22381       software-development\n",
      "Name: labels, Length: 22382, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.502284100Z",
     "start_time": "2024-01-27T17:19:58.774284300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\"\"\"Generate encoding for labels using label encoder\"\"\"\n",
    "multilabel_binarizer = LabelEncoder()\n",
    "multilabel_binarizer.fit(train[\"labels\"]) \n",
    "\n",
    "Y = multilabel_binarizer.transform(train[\"labels\"]) \n",
    "texts = [x[0]+\" \" + x[1] for x in zip(train.title,train.subtitle)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.502284100Z",
     "start_time": "2024-01-27T17:19:58.823284100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22382,)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Notice that the 3 labels have been converted into a numerical value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.502284100Z",
     "start_time": "2024-01-27T17:19:58.839285700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels: ['artificial-intelligence', 'software-development', 'ux'] have been respectively assigned the values: {0, 1, 2}\n",
      "The label of the first article is: software-development and was assigned label index: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'The labels: {list(multilabel_binarizer.classes_)} have been respectively assigned the values: {set(Y)}')\n",
    "print(f'The label of the first article is: {train[\"labels\"][0]} and was assigned label index: {Y[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Basic Word2Vec model prediction\n",
    "\n",
    "We will train the model on the corpus composed of a list of a list of the words per article title + subtitle pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:19:59.920283Z",
     "start_time": "2024-01-27T17:19:58.855284200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code/Demo Share: Palo Alto Firewall Network Infrastructure Automation with Consul-Terraform-Sync IP is broken as a unit of Control! IDENTITY as a unit of control is the key to succeed in discovering, securing and automating your current workflows across any runtime and cloud. Let’s discuss how we can automate Palo Alto Network firewall dynamic address groups using Consul with Terraform. The…\n",
      "['Code/Demo', 'Share:', 'Palo', 'Alto', 'Firewall', 'Network', 'Infrastructure', 'Automation', 'with', 'Consul-Terraform-Sync', 'IP', 'is', 'broken', 'as', 'a', 'unit', 'of', 'Control!', 'IDENTITY', 'as', 'a', 'unit', 'of', 'control', 'is', 'the', 'key', 'to', 'succeed', 'in', 'discovering,', 'securing', 'and', 'automating', 'your', 'current', 'workflows', 'across', 'any', 'runtime', 'and', 'cloud.', 'Let’s', 'discuss', 'how', 'we', 'can', 'automate', 'Palo', 'Alto', 'Network', 'firewall', 'dynamic', 'address', 'groups', 'using', 'Consul', 'with', 'Terraform.', 'The…']\n",
      "We will train on 27718 article descriptions, with 1756693 words in total, with 101496 unique entries.\n"
     ]
    }
   ],
   "source": [
    "all_texts = [x[0]+ \" \" + x[1] for x in zip(final_data.title,final_data.subtitle)]\n",
    "print(all_texts[0])\n",
    "\n",
    "all_texts_split = [text.split(\" \") for text in all_texts]\n",
    "print(all_texts_split[0])\n",
    "\n",
    "unique_values_set = set()\n",
    "for sublist in all_texts_split:\n",
    "    for value in sublist:\n",
    "        unique_values_set.add(value)\n",
    "\n",
    "print(f'We will train on {len(all_texts_split)} article descriptions, with {sum([len(v) for v in all_texts_split])} words in total, with {len(unique_values_set)} unique entries.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:22:48.614285200Z",
     "start_time": "2024-01-27T17:19:59.750312700Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[314], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Train word2vec model on title + subtitles to establish a baseline without network structure\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_texts_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\word2vec.py:429\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m corpus_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_rule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    431\u001b[0m         corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, total_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count,\n\u001b[0;32m    432\u001b[0m         total_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs, start_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[0;32m    433\u001b[0m         end_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha, compute_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\word2vec.py:495\u001b[0m, in \u001b[0;36mWord2Vec.build_vocab\u001b[1;34m(self, corpus_iterable, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count \u001b[38;5;241m=\u001b[39m corpus_count\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words \u001b[38;5;241m=\u001b[39m total_words\n\u001b[1;32m--> 495\u001b[0m report_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_raw_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_raw_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrim_rule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrim_rule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m report_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_memory(vocab_size\u001b[38;5;241m=\u001b[39mreport_values[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_retained_words\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_weights(update\u001b[38;5;241m=\u001b[39mupdate)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\word2vec.py:769\u001b[0m, in \u001b[0;36mWord2Vec.prepare_vocab\u001b[1;34m(self, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_null_word()\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msorted_vocab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m update:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_by_descending_frequency\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhs:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;66;03m# add info about each word's Huffman encoding\u001b[39;00m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_binary_tree()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:758\u001b[0m, in \u001b[0;36mKeyedVectors.sort_by_descending_frequency\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    756\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorting after vectors have been allocated is expensive & error-prone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors[count_sorted_indexes]\n\u001b[1;32m--> 758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_to_index \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mword\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_to_key\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\keyedvectors.py:758\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    756\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msorting after vectors have been allocated is expensive & error-prone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors[count_sorted_indexes]\n\u001b[1;32m--> 758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_to_index \u001b[38;5;241m=\u001b[39m {word: i \u001b[38;5;28;01mfor\u001b[39;00m i, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_to_key)}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\"\"\"Train word2vec model on title + subtitles to establish a baseline without network structure\"\"\"\n",
    "word2vec_model = Word2Vec(all_texts_split, vector_size=128, window=10, epochs=30, sg=1, workers=4,min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sample usage of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:30:07.841555200Z",
     "start_time": "2024-01-27T17:30:07.786530300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The embedding for the word \"Spring\" is [-0.5764087   0.429049    0.24510169 ... -0.22820064  0.5205468\n",
      " -0.43968904], with shape: (128,)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=10)\n",
    "print(f'The embedding for the word \"Spring\" is {word2vec_model.wv[\"Spring\"]}, with shape: {word2vec_model.wv[\"Spring\"].shape}')\n",
    "\n",
    "# Running the model on an unseen word will raise an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:30:11.606523300Z",
     "start_time": "2024-01-27T17:30:08.490498600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape (22382, 128) corresponds to the 128 parameter long encoding of each article.\n",
      "This corresponds to Y array with (22382,) entries, containing the labels for each article.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "embeddings = []\n",
    "\"\"\"Infer word2vec embeddings for article titles and subtitles using trained word2vec model\"\"\"\n",
    "for text in texts:\n",
    "    # Each text is one article (title + subtitle)\n",
    "    embeddings.append(\n",
    "        np.mean(\n",
    "            [word2vec_model.wv[word] for word in text.split(\" \")] # At this point, we will have an array of size (n, 128) where n is the number of words in the title + subtitle\n",
    "            , axis=0 # We compress each column, thus we obtain an array of size (1,128) which represents the embedding of each article (text)\n",
    "        ) # We add the embedding to our list\n",
    "    )\n",
    "\n",
    "X_word2vec = np.vstack(embeddings)\n",
    "print(f'The shape {X_word2vec.shape} corresponds to the 128 parameter long encoding of each article.')\n",
    "print(f'This corresponds to Y array with {Y.shape} entries, containing the labels for each article.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:30:50.700497900Z",
     "start_time": "2024-01-27T17:30:11.609497600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Train a SVM classifier on generated article embeddings\"\"\"\n",
    "svc = SVC()\n",
    "svc.fit(X_word2vec,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:30:51.271497900Z",
     "start_time": "2024-01-27T17:30:50.697499400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape (3950, 128) corresponds to the 128 parameter long encoding of each article in the test data.\n"
     ]
    }
   ],
   "source": [
    "test_embeddings = []\n",
    "test_texts = [x[0]+ \" \" + x[1] for x in zip(test.title,test.subtitle)]\n",
    "\"\"\"Compute embeddings for test samples\"\"\"\n",
    "for text in test_texts:\n",
    "    test_embeddings.append(np.mean([word2vec_model.wv[word] for word in text.split(\" \")], axis=0))\n",
    "X_word2vec_test = np.vstack(test_embeddings)\n",
    "print(f'The shape {X_word2vec_test.shape} corresponds to the 128 parameter long encoding of each article in the test data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:00.037498Z",
     "start_time": "2024-01-27T17:30:51.265497600Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate predictions using the SVM classifier for test articles\"\"\"\n",
    "predictions = svc.predict(X_word2vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:00.055498200Z",
     "start_time": "2024-01-27T17:31:00.033497400Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Encode reference labels\"\"\"\n",
    "Y_test = multilabel_binarizer.transform(test[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Add this point we have a first attempt at predicting the label for articles in our test set, without using the list information at all, rather just analyzing the embeddings of each article's description. We can see that both the predicted and Y_test have the same number of elements (as a sanity check - we are testing on 3950 articles). \n",
    "\n",
    "However, we can already spot that we have not predicted any articles having the \"UX\" label. Granted, these were only 29 out of 3950, or 0.73%, with a similarly low percentage in the training data (0.67%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:00.109497800Z",
     "start_time": "2024-01-27T17:31:00.050498200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3950,)\n",
      "{0, 1}\n",
      "(3950,)\n",
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "print(set(predictions))\n",
    "print(Y_test.shape)\n",
    "print(set(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:00.111498200Z",
     "start_time": "2024-01-27T17:31:00.064497900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.551062034371367\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\"\"\"Compute Macro f1\"\"\"\n",
    "print(metrics.f1_score(Y_test, predictions,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:00.158497100Z",
     "start_time": "2024-01-27T17:31:00.080498700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1899\n",
      "           1       0.84      0.81      0.82      2022\n",
      "           2       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.82      3950\n",
      "   macro avg       0.55      0.55      0.55      3950\n",
      "weighted avg       0.82      0.82      0.82      3950\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can see that because of the low proportion of \"UX\" articles, we get a low f1-score. However, the weighted average suggests a precision of around 82%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph embeddings - Pipeline Overview \n",
    "\n",
    "Our goal is to construct a graph from the given data by connecting nodes that at least share one common subscription list.\n",
    "\n",
    "This step is followed by a random walk to construct node embeddings.\n",
    "\n",
    "Then the node embeddings are employed for the task of topic classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forming the graph - monopartite projection\n",
    "\n",
    "Our goal is to construct a graph from  given data by connecting nodes that at least share one common subscription list. The networkx part has already been written for you. \n",
    "\n",
    "Your task here is to write the module to construct the edges and find isolated nodes and also analyze the resulting graph by reporting number of edges, number of nodes, number of isolated nodes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:00.159498100Z",
     "start_time": "2024-01-27T17:31:00.111498200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from typing import List,Dict\n",
    "\n",
    "def get_nodes_url(data: pd.DataFrame) -> Dict:\n",
    "    \"\"\" Given the dataframe with articles and lists return the set of nodes\n",
    "        Args:\n",
    "        data (pd.DataFrame): The medium dataset\n",
    "    Returns:\n",
    "        nodes: dict maps a url to its main id\"\"\"\n",
    "    nodes = {}\n",
    "    url_to_node = {}\n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"article\"] not in url_to_node:\n",
    "            nodes[index] = [row[\"article\"]]\n",
    "            url_to_node[row[\"article\"]] = index\n",
    "        else:\n",
    "            # add alternative id\n",
    "            nodes[url_to_node[row[\"article\"]]].append(index)\n",
    "    return url_to_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:00.218498700Z",
     "start_time": "2024-01-27T17:31:00.137498500Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_edges(data: pd.DataFrame, nodes: Dict) -> List:\n",
    "    \"\"\" Given the dataframe with articles and lists return the set of edges\n",
    "        Args:\n",
    "        data (pd.DataFrame): The medium dataset\n",
    "        nodes: dict (nodeId: article title)\n",
    "    Returns:\n",
    "            edges (List[tuple]): List of edges\"\"\"\n",
    "    edges = set()\n",
    "    ## START\n",
    "    \n",
    "    # dictionary to get main id from article url\n",
    "    url_to_mainId = get_nodes_url(data)\n",
    "    \n",
    "    # for each list, we will store all the articles that are part of it, then we will create edges between each of the paris of articles part of the same list\n",
    "    lists = {} \n",
    "    for index, row in data.iterrows():\n",
    "        if index in nodes:\n",
    "            mainId = index\n",
    "        else:\n",
    "            # index is an alternative id\n",
    "            mainId = url_to_mainId[row[\"article\"]]\n",
    "        \n",
    "        # since some articles are part of multiple lists we will assign them to each\n",
    "        urls = row[\"list\"].split('; ')\n",
    "        for url in urls:\n",
    "            if url in lists:\n",
    "                lists[url].append(mainId)\n",
    "            else:\n",
    "                lists[url] = [mainId]\n",
    "    for list_values in lists.values():\n",
    "        n = len(list_values)\n",
    "        for i in range(0, n):\n",
    "            for j in range(i+1, n):\n",
    "                edges.add((list_values[i], list_values[j]))\n",
    "    ##END\n",
    "    return list(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:00.242498600Z",
     "start_time": "2024-01-27T17:31:00.171498300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nodes(data: pd.DataFrame) -> Dict:\n",
    "    \"\"\" Given the dataframe with articles and lists return the set of nodes\n",
    "        Args:\n",
    "        data (pd.DataFrame): The medium dataset\n",
    "    Returns:\n",
    "        nodes: dict maps a main id to its url (first element in the value list), then alternative ids (defined below)\"\"\"\n",
    "    nodes = {}\n",
    "    url_to_node = {}\n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"article\"] not in url_to_node:\n",
    "            nodes[index] = [row[\"article\"]]\n",
    "            url_to_node[row[\"article\"]] = index\n",
    "        else:\n",
    "            # add alternative id\n",
    "            nodes[url_to_node[row[\"article\"]]].append(index)\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that, as per our earlier discussion, the article urls are not unique in the full data. Thus, we will modify the get_nodes to reflect this fact. We will use the row index of the first appearance of a url to be the main id. Then, in order to capture eventual repeating values, we will also store the other indexes (alternative ids) of the same article as a list in the returned dictionary. Notice that the urls are also unique in the returned dictionary, linked 1 to 1 to the main id.\n",
    "\n",
    "For example: 0 -> \\[\"url\", 1, 2] means that the article uniquely identified by the \"url\" has the main id 0 (row where it first appear), and alternative ids 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:01.674499400Z",
     "start_time": "2024-01-27T17:31:00.193498700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1058\n",
      "2\n",
      "(26685, ['https://medium.com/@maniakacademy/automating-application-delivery-with-consul-nia-part-1-f5-big-ip-b5e30138be5c', 26875])\n",
      "1054\n"
     ]
    }
   ],
   "source": [
    "nodes = get_nodes(final_data)\n",
    "\n",
    "train_url_set = set(train[\"article\"])\n",
    "train_test_set = set(test[\"article\"])\n",
    "\n",
    "count_alternative_ids = 0\n",
    "max_count = 0\n",
    "example_value = ()\n",
    "\n",
    "duplicated_count_labeled = 0\n",
    "\n",
    "for key, value in nodes.items():\n",
    "    if len(value) > 1:\n",
    "        if value[0] in train_url_set or value[0] in train_test_set:\n",
    "            duplicated_count_labeled+=1\n",
    "        example_value = (key, value)\n",
    "        count_alternative_ids+=1\n",
    "        max_count = max(max_count, len(value))\n",
    "print(count_alternative_ids)\n",
    "print(max_count)\n",
    "print(example_value)\n",
    "\n",
    "print(duplicated_count_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Running our code, we can see that for 1058 unique articles, their url appeared more than once (in fact, twice) in the full data. For each of these cases, we have also stored the alternative id. Moreover, 1054 out of the 1058 articles also appear in our labeled data, so our (complex) pre-processing can be justified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:01.719523700Z",
     "start_time": "2024-01-27T17:31:01.674499400Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "def form_graph(data: pd.DataFrame) -> nx.Graph:\n",
    "    \"\"\"Forms graph from medium article dataset.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The medium dataset\n",
    "\n",
    "    Returns:\n",
    "        G (nx.Graph): The graph.\n",
    "\n",
    "       \"\"\"\n",
    "    # texts = [x[0]+\" \" + x[1] for x in zip(data.title,data.subtitle)]\n",
    "    nodes = get_nodes(data)\n",
    "    edges = get_edges(data, nodes)\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(list(nodes.keys()))\n",
    "    graph.add_edges_from(edges)\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:11.073522700Z",
     "start_time": "2024-01-27T17:31:01.691500100Z"
    }
   },
   "outputs": [],
   "source": [
    "graph = form_graph(final_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:11.096499100Z",
     "start_time": "2024-01-27T17:31:11.075498400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26660\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now that we have created the graph (might take a minute), we can run some analysis on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:11.147497300Z",
     "start_time": "2024-01-27T17:31:11.091498700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 26660. This corresponds to the number of rows in the final data (27718) - the number of rows which refer to the same article url (1058 -> computed earlier).\n",
      "\n",
      "Number of edges: 1711216\n",
      "\n",
      "As a measure of the sparseness of the adjacency matrix, we can check how many edges we have, with respect to how many pairs of nodes exist: 0.002407601150099978, or around 0.2407601150099978%.\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {graph.number_of_nodes()}. This corresponds to the number of rows in the final data ({len(final_data)}) - the number of rows which refer to the same article url ({count_alternative_ids} -> computed earlier).\\n')\n",
    "print(f'Number of edges: {graph.number_of_edges()}\\n')\n",
    "print(f'As a measure of the sparseness of the adjacency matrix, we can check how many edges we have, with respect to how many pairs of nodes exist: {graph.number_of_edges() / (graph.number_of_nodes() ** 2)}, or around {graph.number_of_edges() / (graph.number_of_nodes() ** 2) * 100}%.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2Vec\n",
    "\n",
    "Here the task is to perform random walks on the graph formed in the previous step and compute embeddings for the nodes using the random walk results.\n",
    "\n",
    "You can use gensim to compute embeddings, however for random walks you are expected to implement without relying on networkx. Your weblab assignment would aid you in the same. For gensim you are expected to use Word2Vec. However you  can explore on best ways to configure the hyperparams for your word2vec instance for better donwstream classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:11.193527Z",
     "start_time": "2024-01-27T17:31:11.138497700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 347 isolated nodes.\n"
     ]
    }
   ],
   "source": [
    "# Find isolated nodes with no neighbors before random walks\n",
    "### START\n",
    "isolated = []\n",
    "for node in graph:\n",
    "    if graph.degree(node) == 0:\n",
    "        isolated.append(node)\n",
    "print(f'We have {len(isolated)} isolated nodes.')\n",
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:11.194498100Z",
     "start_time": "2024-01-27T17:31:11.172498200Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def random_walks(G: nx.Graph, num_walks: int, walk_length: int, isolated: List) -> np.ndarray:\n",
    "    \"\"\"Perform random walks on the graph.\n",
    "\n",
    "    Args:\n",
    "        G (nx.Graph): The graph.\n",
    "        num_walks (int): The number of random walks for each node.\n",
    "        walk_length (int): The number of nodes in a random walk.\n",
    "        isolated (List[int]): list of isolated nodeids\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The random walks, shape (n_nodes * num_walks, walk_length)\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    isolated_set = set(isolated)\n",
    "    ### START\n",
    "    for node in sorted(G):\n",
    "        if node in isolated_set:\n",
    "            continue\n",
    "        for walk in range(num_walks):\n",
    "            walk_result = []\n",
    "            cur_node = node\n",
    "            for step in range(walk_length):\n",
    "                walk_result.append(cur_node)\n",
    "                list_neighbors = list(G[cur_node].keys())\n",
    "                cur_node = random.choice(list_neighbors)\n",
    "            result.append(walk_result)\n",
    "    ## END\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:54.206610200Z",
     "start_time": "2024-01-27T17:31:11.183498300Z"
    }
   },
   "outputs": [],
   "source": [
    "walks = random_walks(graph, 8, 15,isolated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:54.232608700Z",
     "start_time": "2024-01-27T17:31:54.208611200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26313.0\n"
     ]
    }
   ],
   "source": [
    "print(len(walks) / 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:54.284608100Z",
     "start_time": "2024-01-27T17:31:54.226610200Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "def fit_node2vec(walks: np.ndarray, vector_size: int, window: int, epochs: int) -> Word2Vec:\n",
    "    \"\"\"Train a Node2Vec model on random walks. Uses the GenSim Word2Vec implementation.\n",
    "\n",
    "    Args:\n",
    "        walks (np.ndarray): The random walks.\n",
    "        vector_size (int): Node representation size.\n",
    "        window (int): Window width.\n",
    "        epochs (int): Number of epochs.\n",
    "\n",
    "    Returns:\n",
    "        Word2Vec: The trained model.\n",
    "        \n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "   ### START\n",
    "    aux = [[str(x) for x in y] for y in walks]\n",
    "    return Word2Vec(sentences=aux, window=window, vector_size=vector_size, epochs = epochs)\n",
    "   ### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:31:54.300608200Z",
     "start_time": "2024-01-27T17:31:54.240611100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210504, 15)\n"
     ]
    }
   ],
   "source": [
    "print(walks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:32:18.889628800Z",
     "start_time": "2024-01-27T17:31:54.257611600Z"
    }
   },
   "outputs": [],
   "source": [
    "model = fit_node2vec(walks, 128, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:32:18.904610600Z",
     "start_time": "2024-01-27T17:32:18.883609100Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nodeids(data: pd.DataFrame):\n",
    "    \"\"\"Get nodeids from graph\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): medium articles dataset\n",
    "\n",
    "    Returns:\n",
    "        nodes (dict): nodeids with mapped article titles\n",
    "    \"\"\"\n",
    "    nodeset = set()\n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"index\"] in nodes:\n",
    "            nodeset.add(row[\"index\"])\n",
    "    return sorted(list(nodeset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:40:20.185370400Z",
     "start_time": "2024-01-27T17:40:18.213371Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Get train and test nodes from the graph\n",
    "    \"\"\"\n",
    "train_nodes = get_nodeids(train)\n",
    "test_nodes = get_nodeids(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:40:26.471948100Z",
     "start_time": "2024-01-27T17:40:26.426948400Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Get node2vec embeddings (nodeid - mainId to embeddings mapping) for full data\n",
    "    \"\"\"\n",
    "node2vec_embeddings = {word: model.wv[word] for word in model.wv.index_to_key}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec + Node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:45:00.866753700Z",
     "start_time": "2024-01-27T17:44:59.226752400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_processed = []\n",
    "for index, row in train.sort_values(by=['index']).iterrows():\n",
    "    if row[\"index\"] in nodes:\n",
    "        Y_processed.append(row[\"labels\"])\n",
    "Y_processed = multilabel_binarizer.transform(Y_processed) \n",
    "\n",
    "Y_test_processed = []\n",
    "for index, row in test.sort_values(by=['index']).iterrows():\n",
    "    if row[\"index\"] in nodes:\n",
    "        Y_test_processed.append(row[\"labels\"])\n",
    "Y_test_processed = multilabel_binarizer.transform(Y_test_processed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:43:42.470784600Z",
     "start_time": "2024-01-27T17:43:36.301785400Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Compute train and test embeddings.\n",
    "Concatenate the word2vec embeddings of article titles\n",
    "with the node2vec embeddings using the dictionary from previous step.\n",
    "Dimension 1 of your embeddings should be 256.\n",
    " Consider isolated nodes and handle them when computing embeddings\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "id_to_title_embedding = []\n",
    "\"\"\"Infer word2vec embeddings for article titles and subtitles using trained word2vec model\"\"\"\n",
    "for index, row in final_data.iterrows():\n",
    "    text = row[\"title\"] + \" \" + row[\"subtitle\"]\n",
    "    # Each text is one article (title + subtitle)\n",
    "    id_to_title_embedding.append(\n",
    "        np.mean(\n",
    "            [word2vec_model.wv[word] for word in text.split(\" \")] # At this point, we will have an array of size (n, 128) where n is the number of words in the title + subtitle\n",
    "            , axis=0 # We compress each column, thus we obtain an array of size (1,128) which represents the embedding of each article (text)\n",
    "        ) # We adad the embedding to our list\n",
    "    )\n",
    "\n",
    "\"\"\"Compute train and test embeddings.\n",
    "Concatenate the word2vec embeddings of article titles\n",
    "with the node2vec embeddings using the dictionary from previous step.\n",
    "Dimension 1 of your embeddings should be 256.\n",
    " Consider isolated nodes and handle them when computing embeddings\"\"\"\n",
    "\n",
    "X_train_n2v_w2v =  np.array(\n",
    "    [ np.concatenate([id_to_title_embedding[x],node2vec_embeddings[str(x)]]) \n",
    "      if x not in isolated \n",
    "      else np.concatenate([id_to_title_embedding[x],np.zeros((128))])  \n",
    "      for idx, x in enumerate(train_nodes)  \n",
    "      ], dtype=np.float32)\n",
    "\n",
    "X_test_n2v_w2v = np.array(\n",
    "    [ np.concatenate([id_to_title_embedding[x],node2vec_embeddings[str(x)]]) \n",
    "      if x not in isolated \n",
    "      else np.concatenate([id_to_title_embedding[x],np.zeros((128))])  \n",
    "      for idx, x in enumerate(test_nodes)  \n",
    "      ], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:43:42.495809100Z",
     "start_time": "2024-01-27T17:43:42.472784700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21531, 256), (3801, 256))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_n2v_w2v.shape,X_test_n2v_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:46:22.327984600Z",
     "start_time": "2024-01-27T17:45:28.765043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_n2v_w2v,Y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-27T17:26:36.018619100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-27T17:26:36.021622100Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_test_n2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:46:43.057255Z",
     "start_time": "2024-01-27T17:46:32.097597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7480864199542775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83      1794\n",
      "           1       0.86      0.79      0.82      1978\n",
      "           2       0.87      0.45      0.59        29\n",
      "\n",
      "    accuracy                           0.83      3801\n",
      "   macro avg       0.84      0.70      0.75      3801\n",
      "weighted avg       0.83      0.83      0.82      3801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = svc.predict(X_test_n2v_w2v)\n",
    "from sklearn import metrics\n",
    "print(metrics.f1_score(Y_test_processed, predictions,average=\"macro\"))\n",
    "print(metrics.classification_report(Y_test_processed, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only node2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:47:18.166084Z",
     "start_time": "2024-01-27T17:47:18.015743900Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_n2v =  np.array([node2vec_embeddings[str(x)] if x not in isolated else np.zeros((128)) for idx, x in enumerate(train_nodes)  ], dtype=np.float32)\n",
    "\n",
    "\n",
    "X_test_n2v =np.array([node2vec_embeddings[str(x)] if x not in isolated else np.zeros((128)) for idx, x in enumerate(test_nodes)  ], dtype=np.float32)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:48:00.805623800Z",
     "start_time": "2024-01-27T17:47:18.327063800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_n2v,Y_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:48:09.358865400Z",
     "start_time": "2024-01-27T17:48:00.803625Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = svc.predict(X_test_n2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:48:09.375865800Z",
     "start_time": "2024-01-27T17:48:09.360865600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717811673917574\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.f1_score(Y_test_processed, predictions,average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-27T17:48:09.406867900Z",
     "start_time": "2024-01-27T17:48:09.377865600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      1794\n",
      "           1       0.85      0.74      0.79      1978\n",
      "           2       0.86      0.41      0.56        29\n",
      "\n",
      "    accuracy                           0.80      3801\n",
      "   macro avg       0.82      0.67      0.72      3801\n",
      "weighted avg       0.80      0.80      0.80      3801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test_processed, predictions))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Compare performance of word2vec only, node2vec embeddings only (above) and word2vec+node2vec settings.\n",
    "  Report your intuition below in text as to why one works better than other and to what extent network structure helps compare dto only using word2vec embeddings of titles and subtitles (first result).\n",
    "\n",
    " You can also plot the tsne plot of embeddings to gain more intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[269], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply t-SNE transformation to reduce dimensions to 2D\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m node_embeddings_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_n2v\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m node_embeddings_2d_both \u001b[38;5;241m=\u001b[39m tsne\u001b[38;5;241m.\u001b[39mfit_transform(X_train_n2v_w2v)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\manifold\\_t_sne.py:1126\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m \n\u001b[0;32m   1107\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;124;03m    Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m-> 1126\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\manifold\\_t_sne.py:1016\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[38;5;66;03m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;66;03m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m degrees_of_freedom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 1016\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tsne\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneighbors_nn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_num_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_num_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\manifold\\_t_sne.py:1068\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[1;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# Learning schedule (part 1): do 250 iteration with lower momentum but\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# higher learning rate controlled via the early exaggeration parameter\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m P \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_exaggeration\n\u001b[1;32m-> 1068\u001b[0m params, kl_divergence, it \u001b[38;5;241m=\u001b[39m \u001b[43m_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m   1071\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[t-SNE] KL divergence after \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m iterations with early exaggeration: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m         \u001b[38;5;241m%\u001b[39m (it \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, kl_divergence)\n\u001b[0;32m   1073\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\manifold\\_t_sne.py:402\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[1;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# only compute the error when needed\u001b[39;00m\n\u001b[0;32m    400\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m check_convergence \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m==\u001b[39m n_iter \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 402\u001b[0m error, grad \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m inc \u001b[38;5;241m=\u001b[39m update \u001b[38;5;241m*\u001b[39m grad \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    405\u001b[0m dec \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minvert(inc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\manifold\\_t_sne.py:283\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[1;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[0;32m    280\u001b[0m indptr \u001b[38;5;241m=\u001b[39m P\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    282\u001b[0m grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X_embedded\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 283\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[43m_barnes_hut_tsne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_P\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m (degrees_of_freedom \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m/\u001b[39m degrees_of_freedom\n\u001b[0;32m    297\u001b[0m grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply t-SNE transformation to reduce dimensions to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "node_embeddings_2d = tsne.fit_transform(X_train_n2v)\n",
    "node_embeddings_2d_both = tsne.fit_transform(X_train_n2v_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the 2D embeddings with color based on labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    node_embeddings_2d[:, 0],\n",
    "    node_embeddings_2d[:, 1],\n",
    "    c=Y_processed,\n",
    "    cmap='viridis',  # You can choose a different colormap\n",
    "    marker='o'\n",
    "    s=10\n",
    ")\n",
    "plt.title('t-SNE Visualization of Node Embeddings')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot of the 2D embeddings with color based on labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    node_embeddings_2d_both[:, 0],\n",
    "    node_embeddings_2d_both[:, 1],\n",
    "    c=Y_processed,\n",
    "    cmap='viridis',  # You can choose a different colormap\n",
    "    marker='o'\n",
    "    s=10\n",
    ")\n",
    "plt.title('t-SNE Visualization of Node Embeddings')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
